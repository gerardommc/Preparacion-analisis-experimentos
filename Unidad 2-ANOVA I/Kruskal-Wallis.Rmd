---
title: "Prueba de Kruskal-Wallis"
author: "Gerardo Martín"
date: "4/3/2021"
output: 
      bookdown::html_document2:
            toc: true 
            number_sections: true
            toc_float: true
            theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Hasta este momento hemos visto varios ejemplos del modelo ANOVA como herramienta para comparar medias entre tratamientos. Para que los resultados de los análisis hechos con ANOVA sean confiables es necesario que los datos cumplan con ciertos supuestos y que el cumplimiento de estos supuestos quede reflejado en los residuales del análisis. Cuando los datos no cumplen con los supuestos necesarios para confiar en los resultados de ANOVA debemos emplear otras herramientas, una de ellas, y la más sencilla de todas, es la prueba de [Kruskal-Wallis](https://es.wikipedia.org/wiki/Prueba_de_Kruskal-Wallis).

Al igual que ANOVA, Kruskal-Wallis sirve para probal la hipótesis nula $H_0$ de no-diferencias entre dos ó más grupos de datos, sin asumir ningún tipo de distribución, a diferencia de ANOVA. Esta es la principal y única ventaja de la prueba de Kruskal-Wallis en comparación con ANOVA.

La principal limitación de Kruskal-Wallis es que no es un método paramétrico, como sí lo es ANOVA. Los métodos paramétricos se basan en supuestos relativamente rígidos que hacen sobre la distribución estadística de los datos, pero en general es más fácil aplicarlos a diseños experimentales complejos pues permiten, como su nombre lo indica, estimar parámetros como la media-$\mu$ y varianza-$\sigma^2$. Los métodos no paramétricos no están basados en modelos matemáticos *a priori* (la [distribución normal](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_normal), p. ej.), en cambio hacen una serie de cálculos matemáticos basados en la frecuencia de las observaciones. Es por esta razón que también se les llama análisis guiados por los datos. De aquí que la prueba de Kruskal-Wallis no puede ser usada para analizar datos experimentales con efectos aleatorios.

## Otros métodos no paramétricos

Al igual que ANOVA, la prueba del estadístico *t*-student que se usa para comparar medias de pares de tratamientos, existen alternativas no paramétricas para pares de muestras. La primera alternativa no paramétrica es la [prueba de Wilcoxon](https://es.wikipedia.org/wiki/Prueba_de_los_rangos_con_signo_de_Wilcoxon) que hace la comparación de pares de medias de variables con distribuciones diferentes a la normal. Una prueba similar a la de Wilcoxon es la [prueba de Kolmogorov-Smirnov](https://es.wikipedia.org/wiki/Prueba_de_Kolmogorov-Smirnov), aunque la hipótesis que se prueba es que el par de grupos de datos provienen de distribuciones estadísticas diferentes.

# Prueba de Kruskal-Wallis en **R**

Para hacer esta prueba en **R** nos se requiere de ningún paquete especial, y se usa la función `kruskal.test`. El primer argumento que se da a la función es la fórmula del modelo del mismo como que con `aov` y `lm`: `y ~ x`. El segundo de la función es el nombre de la base de datos que contiene a $y$ y $x$. Igual que antes simularemos una base de datos sencilla, para analizar con ANOVA y Kruskal-Wallis y comparar los resultados.

Aquí los detalles de la generación de los datos:

```{r}
set.seed(123)

y1 <- exp(rnorm(100, 0, 1))
y2 <- exp(rnorm(100, 0.1, 1))
y3 <- exp(rnorm(100, 0.2, 1.5))

trats <- rep(c("A", "B", "C"), each = 100)

base.datos <- data.frame(Valor = c(y1, y2, y3),
                         Tratamiento = trats)

```

Primero verifiquemos la distribución estadística de los datos:

```{r Cajas-1, fig.height=4, fig.width=6, fig.cap="Gráfico de cajas de los datos simulados.", fig.align="center"}
boxplot(Valor ~ Tratamiento, base.datos)
points(c(1, 2, 3),
       c(mean(y1), mean(y2), mean(y3)),
       col = "red", pch = 20, cex = 1.5)
```

Y se puede apreciar claramente que los datos son asimétricos alrededor de la mediana. Ahora vamos a comparar los resultados de ANOVA con Kruskal-Wallis

```{r}
modelo.1 <- aov(Valor ~ Tratamiento, data = base.datos)
modelo.2 <- kruskal.test(Valor ~ Tratamiento, data = base.datos)
```

Los resultados de ANOVA:
```{r}
summary(modelo.1)
```

sugieren que hay diferencias significativas entre tratamientos ($P < 0.05$), mientras que los resultados de de Kruskal-Wallis:

```{r}
modelo.2
```

indican lo contrario ($P > 0.05$).

Para decidir a qué método le hacemos caso, hay que hacer el diagnóstico posterior, de entrada sabemos que `Valor` no cumple con el supuesto de homogeneidad de varianza. Veamos las gráficas de los residuales:

```{r diagnostico, fig.height=7, fig.width=6, fig.align="center", fig.cap="Gráficas de diagnóstico de `modelo.1`"}
par(mfrow = c(2,2))
plot(modelo.1)
```

Y efectivamente, la línea roja de la primera gráfica no es horizontal, y los puntos de la segunda gráfica tampoco siguen de cerca la línea punteada, con lo que concluimos que ANOVA es inadecuado para rechazar la hipótesis nula de no diferencia entre tratamientos.

Para cerrar, debido a que Kruskal-Wallis no hace ningún supuesto de distribución de datos, no es necesario hacer gráficas diagnósticas. Lo que sí es necesario para analizar datos con esta prueba es descartar la posible existencia de pseudo-replicación y/o efectos aleatorios.

# Aplicación del conocimiento

[Regresar al índice del curso](../index.html)